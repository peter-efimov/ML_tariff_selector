{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение в машинное обучение - Проект"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "\n",
    "В рамках данного проекта необходимо обучить модель, которая будет рекомендовать пользователю мобильной сети Мегалайн наиболее подходящий тариф - ультра или смарт. В распоряжении есть датасет, изученный в предыдущем проекте. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем библиотеки\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим и рассмотрим датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0\n",
       "5   58.0   344.56      21.0  15823.37         0\n",
       "6   57.0   431.64      20.0   3738.90         1\n",
       "7   15.0   132.40       6.0  21911.60         0\n",
       "8    7.0    43.39       3.0   2538.67         1\n",
       "9   90.0   665.41      38.0  17358.61         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('/Users/peterefimov/Dropbox/DS_projects/5. Machine Learning. Project./users_behavior.csv')\n",
    "data = pd.read_csv('/datasets/users_behavior.csv')\n",
    "\n",
    "display(data.head(10))\n",
    "print()\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам доступны данные о 3214 пользователях, уже сменивших тариф: количество звонков, суммарное количество потраченных минут, отправленных сообщений и потраченного интернет-трафика, а также выбранный ими тариф. Данные предобработаны, пропущенные значения отсутствуют. Преобразование типов делать не будем, т.к. модели справятся с числами типа float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод по этапу\n",
    "Данные загружены, рассмотрены, предобработка не требуется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание выборок\n",
    "\n",
    "Сперва посмотрим на зависимость признаков друг от друга. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAF2CAYAAAC4dEhVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXwV1f3/8dfnZiHshFVk31xYRCyCFnfRr9IqbbWLW1ur0v5aC1201VotUmut1bbW2q+iVau1Wqt+WxesW10RWRUFBEEWCXsIkACSkOTz+2MGuAlJ7r0kN5dJ3s/HYx7cuXPmzGfukORzzzlzxtwdERERkcYWy3QAIiIi0jwpCREREZGMUBIiIiIiGaEkRERERDJCSYiIiIhkhJIQERERyQglISIiIpIRSkKkQZjZSjMrM7PO1d5/z8zczPpmJjIRETlYKQmRhrQCuGDPipkNA1pmLhwRETmYKQmRhvQw8PW49W8AD8UXMLPPmdm7ZlZsZqvNbHLctvlmtt3MPjWzyvD1djP7WbjdzWyimS03s0Iz+62ZxcJt3zSzt+Lq+klYfmy4PtnM/ha3PTu+hcbMBpjZf81sc1j3I2bWobYTDfcdGL4+NzyX/uF6ezN7yMw2mdkqM/t5tTinm9mdZrbNzBab2elx9b5mZr82s1nh9n+bWce47ceZ2dtmtjX8vE6pFteDYYvUns+xIG7bF8xsiZmVhNvjz/81M7s8ruxYM1tZrd6b4tanhftnV9/fzGJm9kH8sWv5/HbEXeMyM3sw3NY33D7BzNaa2Toz+3HcvtWv5Z+rXY9bw2tYYmbvmNnQavVmx+37tz3/B80s38yeDa/blvB1z2rXZs85Dgiv+Tlx5/zz8HpvDK9/+2rH3XOuC6pfN5HmSkmINKR3gHZmdqSZZQFfBf5WrcwOgkSlA/A54P+Z2RcA3H24u7cBzgbWunubcLk5bv8vAiOBY4DxwLeqB2Fm+cBEYGsKsRvwa+BQ4EigFzA54U5mJwN3A+PcfXn49p1Ae6A/cHJ4vpfG7TYaWA50Bn4BPBWfaITlvxXGUg78MTxWD+A54CagI3AV8KSZdYnbNwb8Ju5zjHc38Gt3b0vw+R+Q8A/oUXUU+QaQn0RVw/dcY+DWGrafCgwCzgSu2ZNQVotlEPuf51+A3gTn+F/gxiRigeCzewDoE+7/KfCnGo55CPACcJ27PxO+/c1wOZXgurepYd8OQFvgceC2JGMSadKUhEhD29MacgawGFgTv9HdX3P3D9y90t3fBx4l+EOdrN+4e5G7fwL8gbjunzjXAfcD25Kt1N2XuftL7l7q7puA3yUR1wjgaeAid/8AIC75utbdS9x9JXA7cEncfhuBP7j7bnf/B7CEICHb42F3X+DuO4Drga+E9V4MTHP3aeHn9xIwBxgXt28uUFZHzNlmZgnOq1bhvrcCN9SyPS+M+ZcHeow4N7r7jvCzfYCar/Wvqx/L3Ze4+06CxBJgXjIHc/fN7v6ku+909xLgV+z/f6AD8CLwiLvHt/JdBPzO3Ze7+3bgWuBr8a0uIQOygM3JxCTS1CkJkYb2MHAhwbfCh6pvNLPRZvZq2OS9DfgOQYtAslbHvV5F0FoQX39v4CvAb1MJ2sy6mtljZrbGzIoJWnASxXUfsJQg4dqjM0EisKpanD3i1td41SdHVj+P6ueYE9bbB/hy2BWz1cy2AicA3ePKdwS21BLvN4FrCL7hF9Z5ZrX7CsEf0P/Wsn0SQSvBkgOsP16iaz0aOAL4a/UdzezPBK1uFwKvVttcGPf5fSVun1Zmdk/YpVIMvAF0CBPAPaYA24HTLexiCx3K/tc8G+gWf9xw3x8Av6n1rEWaESUh0qDcfRXBANVxwFM1FPk7QetBL3dvT9BFkMo3815xr3sDa6ttvwm4Nfwmm4pfAw4c5e7tCFodEsX1A+DzwGVmdkz4XiGwmyBhiI8zvkWoR7XWiOrnUf0cd4f1riZoJekQt7R291viyh8GfFRLvC8RtA5dQmqJ3x45BK0OP61le0fgSpLv/kgk0bW+FbjG3Suq7+ju3wVaESSj/1dtc+c9nx9B18gePwYOB0aH/wdOCt+Pv1aPEyR+EJzrHmvZ/5qXAxuqHbcVQTfik2amQdvS7CkJkXS4DDgt7E6ori1Q5O67zGwUwTfVVFwdDiDsRfCt+x9x2wYSjLe45wBibkvwLXVrOPbi6iT2edPd1xOMzXjAzHLCP4iPA78ys7Zm1gf4EVXHxnQFJppZjpl9mWAMyrS47Reb2WAza0XwzfuJsN6/AeeY2f+YWZaZ5ZnZKWbW04KBtt8hGIvwFjX7McFYm38m+ZlUdwnwdtiNVpMfAH8JP5OGcH3YOjGEYExN/LU+DXB3f7b6TmY2NGylMKAFQctPMtqGZbeGY3R+UUOZt9y9kmDMzg0WDkYm6Fb8oZn1M7M2wM3AP9y9vIY6KgjGDOUmGZdIk6UkRBqcu3/s7nNq2fxdYIqZlRCMK3i8lnK1+TcwF3iPYJDmX+K2dQN+7u67a9n3i2ZWEN61sTJ8b0b4740Eg123hfXW1IpTI3d/mKCV4mfhW98n6ApYTpAQ/J1gjMoeMwkGXBYSjDs4393jxwg8DDwIrAfyCAbZ4u6rCb5F/wzYFB7zaoKf48sI/lCPD8dDVGFmAwiSkO/WcSq3xn0+jwI9zSw+YcknGO9RmywadsDl68Ay4BXgNnd/MW5bd+Antez3a4Iuqc3A+dQ8lqQmfyC4pbyQYJD1f2or6O4fAbcA94WtWvcTXLc3CFoCdxH8P4i31cy2E3RTftvdkx6zJNJUWdWuaZGDl5k5MMjdlzVgnSvdvW9D1ZfE8b4JXO7uJ9Sy/TXgb+5+X2PFVBsLbt990N1PycBxVwA5tbQkiEgToZYQae5q67qQoGtibqaDEJGmS0mINGvufnGmYzhYufsGd/9x4pIi0hyY2f3hZHwLatluZvZHM1tmZu/HDdivvU51x4iIiEgiZnYSwQD+h9x9aA3bxxGMhRpHcJPAHe4+uq461RIiIiIiCbn7G0BRHUXGEyQo7u7vEMyz072O8kpCREREpEH0oOokgwVUnahxP9WnFE6L53IOV59PRLXopqkMouzGz/w50yHIARp8/JBMhyD1dM81HQ/4EQmpaoi/s58v/+jbwIS4t6a6+9QUqqjpfOuMq1GSEBERETm4hQlHKklHdQVUnem4J/vPdFyFkhAREZGIs5xGa3Spy9PAlWb2GMHA1G3uvq6uHZSEiIiIRFwsO/1JiJk9CpwCdA5nVv4FwTOlcPe7CR4/MY5gpuOdBLM410lJiIiISMRZTvrvM3H3Oh+BED4d/Hup1KkkREREJOIaoyUkHXSLroiIiGSEWkJEREQi7iAZmJoyJSEiIiIRF9XuGCUhIiIiEaeWEBEREcmIqLaEaGCqiIiIZIRaQkRERCLOsqLZEqIkREREJOJiSkJEREQkEywWzSREY0JEREQkI9QSIiIiEnGWFc02BSUhIiIiEacxISIiIpIRUR0ToiREREQk4qLaEhLNTiQRERGJPLWEiIiIRJwmKxMREZGMsFg0OzaUhIiIiEScBqaKiIhIRmhgqoiIiEgK1BIiIiISceqOERERkYzQwFQRERHJiKi2hEQzdRIREZHIU0uIiIhIxEX17hglISIiIhEX1e4YJSEiIiIRp4GpIiIikhFRbQmJZuokIiIikaeWEBERkYiLakuIkpB6OOrem+k67hTKNm7mjRHnZDocqabTKWM47MafYllZrHn0KVbd9Zcq2/N6dGfw7VPI6dSR8q3bWDDxWkrXbQBg4HU/pPNpJ2GxGJvfnMFHN9ySiVNo1kaNyGfSFf2JxYxnX1rPI08WVNk+fHA7Jl4+gP59W3PjbYt57e3Cvdv+3zf6cvzIjpgZc+Zv4Y57lzd2+M3akH45fGVsK2IxeGt+KS+8s6vK9rHH5jFmeAsqK53tO52/TttBUXElAF86pSVDB+QAMG36LuYsLmv0+KOoMZIQMzsLuAPIAu5z91uqbe8D3A90AYqAi929YL+K4qg7ph4K/voUsz5/eabDkJrEYhx+03W8d8l3mXHqeA4ZfzatB/WvUmTQ9Vex7olnmHnGeSz//d0MvGYSAO0/M5wOI0fwzhnnMeP0L9Ju+FDyjx+ZibNotmIx+NG3B3DVjQu55Mq5jD2xC317tapSZkNhKTffsYSX39hY5f2hR7Rl2JHt+OakeXxj4lyOGNiWo4e2b8zwmzUzuODMVtz5eAmT793GsYNz6d6p6p+aTzaUc/OD2/jl/cXMXVLGeae2BGDogBx6dcvmpvuLueWhYs4cnUdebibOInosFqv3Umf9ZlnAXcDZwGDgAjMbXK3YbcBD7n4UMAX4daK4lYTUQ9Fbc9hdtC3TYUgN2h89jE9XfsKnnxTgu8vZ8O/n6XLmqVXKtB7Un6LpMwHY8vasfdsdYi1aEMvNIZabSyw7m9JNmxv7FJq1Iwe1Zc36XazbsIvycueVNzdxwqiOVcqs31jKx6t24pVV93WH3JwY2dkxcrJjZGcbW7bq23Rj6dc9m41bKincVklFJcxZVMbwQVUziY8+KWd3efB6xdpyOrQN/hQd2imLpat3U+lQthtWb6xgSH9lIcmIZVm9lwRGAcvcfbm7lwGPAeOrlRkMvBK+frWG7fvHneJ5AmBmMTNrdyD7ijSGFt27smvd+r3ru9ZvoEX3blXKbP/wI7qOGwtAl7NPJ7ttG3I6tGfbvPlseXsWJ879LyfN+y+bX5/OzmUrGjX+5q5LpxZsLCzdu75pcxmdO7VIat+FS0qY98E2/vXAaP714GhmvbuFVQWfpitUqaZDW2NLScXe9S0llXuTjJqMOaoFC5fvBmD1xnKG9M8hJxtatzQO75NNfjt9V24sZjbBzObELRPiNvcAVsetF4TvxZsPnBe+/iLQ1sw61XXMpK+umf3dzNqZWWtgEbDEzK5Odn+RxlVDVu9eZfWjX95G/nEjGf2fx8k/biS71m2gsqKCln170XpQf946dixvjjyd/DGj6TD6M40Ut9TKExcB6HFIHn17teK8y2bypW/N5JhhHRg+WN+ZDkajh+TS55BsXpwZjBn5cGU5Cz7ezU8vacfl57Zh+ZpyKiuTvPDNnMWs3ou7T3X3kXHL1PhD1HDY6hfnKuBkM3sXOBlYA5TXFXcqA1MHu3uxmV0ETAN+CswFfltT4TCDmgBwZawrZ8U6pHAokfopXbeBvO6H7F3PO6Qbpeurjh0o27CJ96/4IQBZrVrSddwZVJRsp+tF57Nt3vtU7Ay+PW9+9S3aH3MUW2fObbwTaOY2bS6la+d9LR9dOuVSWFRaxx77nHR8JxYuKebTXUE/zcx5WxhyeDvmLypOS6xS1dYSJ79t1t71/LYxtpZU7lfuiD7ZnH18S27/ezHl+xpOeH7GLp6fESQll53Tmo1F++8r+2uEycoKgF5x6z2BtfEF3H0t8CUAM2sDnOfudY5ZSCXqHDPLAb4A/Nvdd1PHd5P4jEoJiDS24vkLaNmvD3m9emA52XQbfzabXnqtSpmc/A7BKDqg75WXs/Yf/wfArjXr6HDcSCwrC8vOJv+4z7Bjqe6uaEyLl5bQs3se3bu2IDvbOP3ELrw1qyipfTdsKuXooe3JikFWlnH0kPasLNiZ5ohlj5XryunaMUan9jGyYjBycC7zl+2uUqZXtywuPqs1f36yhJKd+/6MmEHrvOBnskeXLHp0zWLRiqr7Ss0aoiUkgdnAIDPrZ2a5wNeAp6vEYNbZzPbkFdcS3ClTp1RaQu4BVhL0+bwR3orTrL9aHP3w7XQ6eRS5nfM5bcXrLJ1yJ6sfeCLTYQngFRUsuf5mRjxyNxbLYu0//o8dH31M/6u+R/H8hRS+9Br5nz2WgddMwt3ZOnMui6/7FQAbnnuJ/DGjOe7lp3B3Nr82ncKXX8/wGTUvFZXw+6kfc/vkocRixnOvbGDl6p1cdmEfFi8rYfqsIo4Y2IZfXTuYtm2y+eyxHfnWBb35+vfn8drbhRwzrAMP/jHoQps5r4i3ZyeXwEj9VTo89uJOJn21LTGD6e+Xsq6wgnNObMmqdeW8v2w3553aiha5xoQvtAGgqLiSPz+5nawYXHVx0HW2q9S5/5kdqDfm4ODu5WZ2JfACwS2697v7QjObAsxx96eBU4Bfm5kDbwDfS1SvuR/4FTazbHevs78H4Lmcw/XfKKJadNPI9Ci78TN/znQIcoAGHz8k0yFIPd1zTcdGm0Fs1YQv1PvvbJ+p/2r0Gc8StoSY2Y8SFPldA8UiIiIiB6ApP8CubdqjEBERkQPWZKdtd/cbGyMQEREROTBNtiXEzP5Y13Z3n9hw4YiIiEhzkUx3jCZHEBEROZhZ0+2O+WtjBCIiIiIHpsmOCdnDzLoQzJI6GMjb8767n5aGuERERCRJUR0TkkrUjwAfAv2AGwkmLpudhphEREQkBY0wY2papJKEdHL3vwC73f11d/8WcFya4hIREZEmLpVp2/dM4L/OzD5H8OCang0fkoiIiKQiqt0xqSQhN5lZe+DHwJ1AO+AHaYlKREREkhbVgamppE5fJnjWzAJ3PxU4A/hiesISERGRZDWHMSFHufvWPSvuXgSMaPiQREREpDlIpTsmZmb57r4FwMw6pri/iIiIpEMzGBNyO/C2mT0BOPAV4FdpiUpERESSZk11xtQ93P0hM5sDnAYY8CV3X5S2yERERCQpzeHuGMKkQ4mHiIjIQaQ53B0jIiIi0mA0sFRERCTqmkN3jIiIiBx8otodoyREREQk4szUEiIiIiKZENGWkGimTiIiIhJ5agkRERGJuGYxT4iIiIgcfDQwVURERDIjogNToxm1iIiIRJ5aQkRERCJO3TEiIiKSGRqYKiIiIplgFs2WkGimTiIiIrJPLFb/JQEzO8vMlpjZMjO7pobtvc3sVTN718zeN7NxCcM+wNMVERGRZsLMsoC7gLOBwcAFZja4WrGfA4+7+wjga8CfE9Wr7hgREZGIa4SBqaOAZe6+HMDMHgPGA4viyjjQLnzdHlibqFIlISIiIlGX/nlCegCr49YLgNHVykwGXjSz7wOtgbGJKlV3jIiISNTFrN6LmU0wszlxy4S4I9TU1OLV1i8AHnT3nsA44GFL8HhftYSIiIhEXIK/9Ulx96nA1Fo2FwC94tZ7sn93y2XAWWFdM8wsD+gMbKztmI2ShLToltsYh5E0KN1QlukQpB68sjLTIcgBqqjQtZODymxgkJn1A9YQDDy9sFqZT4DTgQfN7EggD9hUV6VqCREREYm6NA9MdfdyM7sSeAHIAu5394VmNgWY4+5PAz8G7jWzHxJ01XzT3at32VShJERERCTirBFmTHX3acC0au/dEPd6ETAmlTqVhIiIiESdZkwVERERSZ5aQkRERKJOD7ATERGRjIhod4ySEBERkYhrjIGp6aAkREREJOrSP217WkQzahEREYk8tYSIiIhEXfqfopsWSkJEREQiriGeHZMJSkJERESiLqItIdFMnURERCTy1BIiIiISdeqOERERkYzQZGUiIiKSEZqsTERERDIiot0x0YxaREREIk8tISIiIlEX0Vt0lYSIiIhEXUS7Y5SEiIiIRJ3ujhEREZGMiOjdMdGMWkRERCJPLSEiIiJRp+4YERERyQgNTBUREZGM0JgQERERkeSpJURERCTqNCZEREREMkJjQkRERCQj1BIiIiIiGaGBqSIiIiLJU0uIiIhIxHlEu2PUEiIiIhJ1Fqv/kugQZmeZ2RIzW2Zm19Sw/fdm9l64fGRmWxPVqZYQERGRqEvz3TFmlgXcBZwBFACzzexpd1+0p4y7/zCu/PeBEYnqVUuIiIhIxLlZvZcERgHL3H25u5cBjwHj6yh/AfBookrVElKHTqeM4bAbf4plZbHm0adYdddfqmzP69GdwbdPIadTR8q3bmPBxGspXbcBgIHX/ZDOp52ExWJsfnMGH91wSyZOQWpx1L0303XcKZRt3MwbI87JdDhSg9HH5DPpioHEYsazL63jb0+srrJ9+JD2TLxiAAP6tmHyrYt47e1CAEYM68DEywfsLde7Zysm/3YRb76zuVHjb86G9M/hgjNbEzPjzfd28fyMT6tsP2NUHicenUdlJZTsrOSBZ7dTVFwJwPmntWLYwFxiBotW7ObRF3dk4hSaJTObAEyIe2uqu08NX/cA4n8IC4DRtdTTB+gH/DfRMdUSUptYjMNvuo73LvkuM04dzyHjz6b1oP5Vigy6/irWPfEMM884j+W/v5uB10wCoP1nhtNh5AjeOeM8Zpz+RdoNH0r+8SMzcRZSi4K/PsWsz1+e6TCkFrEY/Og7g7hq8gdc/L3ZjD2pK317tapSZsOmXdz8hyW8/PqGKu+/+8FWLp00l0snzWXidfMpLa1g1rtbGjP8Zs0MLjqrDX94rJjr79nCqCEt6N45q0qZTzZUcNP9W5l831bmLi7jy6e3BmBAj2wG9sxh8r1buWHqVvp2z+bw3jmZOI3oaYAxIe4+1d1Hxi1T449Qw1G9lmi+Bjzh7hWJwlYSUov2Rw/j05Wf8OknBfjucjb8+3m6nHlqlTKtB/WnaPpMALa8PWvfdodYixbEcnOI5eYSy86mdJO+hR1Mit6aw+6ibZkOQ2px5KB2FKz7lLUbdlFe7rz8xkZOGN2pSpn1G0v5eOUOKmv7NQicOqYL78wtorS0Ms0Ryx79Ds1mY1EFhVsrqaiEWYtKOfqw3CpllqzaTVl58PrjNbvJbxv8KXIgJ9vIzoKcLMjKguIdunZJMav/UrcCoFfcek9gbS1lv0YSXTGQQhJiZreaWTszyzGzV8ys0MwuTnb/qGnRvSu71q3fu75r/QZadO9Wpcz2Dz+i67ixAHQ5+3Sy27Yhp0N7ts2bz5a3Z3Hi3P9y0rz/svn16exctqJR4xeJsi6dctlYWLp3fdPmUrp0apFyPaef2IWX39jYkKFJAvltY2wp2Zc4bCmu3Jtk1OTEo/P44OMyAJavKWfxqjJun9SR2yZ1ZOHy3azbnPDLtEDQfFjfpW6zgUFm1s/McgkSjaerFzKzw4F8YEZSYadwime6ezHweYKM6DDg6toKm9kEM5tjZnOe21GUwmEOFjVkhV71K9dHv7yN/ONGMvo/j5N/3Eh2rdtAZUUFLfv2ovWg/rx17FjeHHk6+WNG02H0ZxopbpHoq+lLmdfR4lGTTvm59O/bmpnz1BWTabVdu+OGtqBP92xeeCcYM9I1P0b3ztlc/ccirv5jEUf0yWFQLw1dPBi4ezlwJfAC8CHwuLsvNLMpZnZuXNELgMfck/uJTeXq7umYGwc86u5FVkfzTdiXNBXg5Z7DUvz1kXml6zaQ1/2Qvet5h3SjdH3Vb1RlGzbx/hXBHUlZrVrSddwZVJRsp+tF57Nt3vtU7Ax+sDa/+hbtjzmKrTPnNt4JiETYxsIyunbe1/LRpVMLCotK69hjf6ed0IU3ZxRSURG5Xz+RtqWkastHfrsYW7fv36VyZN8cPjemJbc+vI3ysLFjxOEtWL5mN6W7g/UPPi5jQI8clq4ub4zQI60xJitz92nAtGrv3VBtfXIqdabSEvKMmS0GRgKvmFkXYFcqB4uS4vkLaNmvD3m9emA52XQbfzabXnqtSpmc/A57v7L1vfJy1v7j/wDYtWYdHY4biWVlYdnZ5B/3GXYsXd7YpyASWYuXFtPr0JZ075ZHdrYx9qSuTJ+V2riqsSd15aU3NqUpQqnNyrXldOuYRef2MbJiMGpwC+Z/VFalTK9uWVwyrg13Pl5Myc59SWLRtgoO651DzCArBof3zlF3TLIaYbKydEi6JcTdrzGz3wDF7l5hZjup+x7hSPOKCpZcfzMjHrkbi2Wx9h//x46PPqb/Vd+jeP5CCl96jfzPHsvAaybh7mydOZfF1/0KgA3PvUT+mNEc9/JTuDubX5tO4cuvZ/iMJN7RD99Op5NHkds5n9NWvM7SKXey+oEnMh2WhCoq4Xd3L+N3Nw4jFjOee3k9Kz7ZyWUX9WXx0hKmz9rMEYPacvPPhtC2TTZjju3EZRf15ZLvzQHgkK4t6NqlBe8tSDhhozSwSoe/v7CdH1zQnlgMps/fxdrCCsaf1IqV68qZvzS4GyYvx/jOee2AIPn40z9LmLO4jCP65nDjhA64w4Llu5m/tCzBEQXAM5RE1Jcl2W2DmbUCfgT0dvcJZjYIONzdn020bxS7YyRQukG/AKLs12dNTVxIDkpHHDck0yFIPd13XedGe6DL9pnP1PvvbJvR5zT6A2hSSZ0eAMqAz4brBcBNDR6RiIiINAupDEwd4O5fNbMLANz9U6trZKqIiIg0iqh2x6SShJSZWUvCGdLMbACQ2nB1ERERaXgRbRNIJQmZDPwH6GVmjwBjgEvTEZSIiIikoKm3hLj7i2Y2FziOYCavSe5emLbIREREJCmNMU9IOqQybfsr7r7Z3Z9z92fdvdDMXklncCIiItJ0JWwJMbM8oBXQ2czy2TefeTvg0DTGJiIiIslowt0x3wZ+QJBwzIt7vxi4Kx1BiYiISPK8puedRUDCJMTd7wDuMLPvu/udjRCTiIiIpKA53KK7zcy+Xv1Nd3+oAeMRERGRZiKVJOTYuNd5wOkE3TNKQkRERDKpqbeEuPv349fNrD3wcINHJCIiIimJ6i26qbSEVLcTGNRQgYiIiMiBafJjQszsGcIp2wnmFxkMPJ6OoERERCQFzaAl5La41+XAKncvaOB4REREpJlIZUzI6+kMRERERA5MVLtjUpm2/UtmttTMtplZsZmVmFlxOoMTERGRxByr95IJqXTH3Aqc4+4fpisYERERSV1UW0JSSUI2KAERERE5CDWDgalzzOwfwL+A0j1vuvtTDR6ViIiINHmpJCHtCOYGOTPuPQeUhIiIiGSQJz/E86CSyt0xl6YzEBERETkwTXbGVDP7ibvfamZ3sm+ysr3cfWJaIhMREZGkNOWBqXsGo86hhiRERERE5EAkTELc/Znw5SLgZ0DfuP0cPUVXREQkozI1z0d9pTIw9W/A1cAHQGV6whEREZFUNeXumD02ufvTaYtEREREDkiTHZga5xdmdh/wCponRERE5KDRGN0xZnYWcAeQBdzn7rfUUOYrwKTsqlQAACAASURBVGSC4Rrz3f3CuupMJQm5FDgCyGFfd4zmCREREWnizCwLuAs4AygAZpvZ0+6+KK7MIOBaYIy7bzGzronqTSUJGe7uw1KMW0RERNKsEcaEjAKWuftyADN7DBhPcNPKHlcAd7n7FgB335io0lSifsfMBqdQXkRERBpBIzxFtwewOm69IHwv3mHAYWY23czeCbtv6pRKS8gJwDfMbAXBmBAD3N2PSqEOERERaWAN0RJiZhOACXFvTXX3qXs213TYauvZwCDgFKAn8KaZDXX3rbUdM5UkJGFGIyIiIo2vIQamhgnH1Fo2FwC94tZ7AmtrKPOOu+8GVpjZEoKkZHZtx0zl2TGrki0rIiIiTcpsYJCZ9QPWAF8Dqt/58i/gAuBBM+tM0D2zvK5KU2kJERERkYNQugemunu5mV0JvEBwi+797r7QzKYAc8J5xF4AzjSzRUAFcLW7b66rXnNP/+NgThz/pp45E1Feqclxo+za/0xIXEgOSr8//5FMhyD19PKjIxttBrHlH39c77+z/QcMaPQZz9QSIiIiEnFRnTE1mpPNi4iISOSpJURERCTi3KPZEqIkREREJOI8oh0bSkJEREQirjEeYJcOSkJEREQiLqpJSDTbb0RERCTy1BIiIiIScVFtCVESIiIiEnFKQkRERCQjonqLrsaEiIiISEaoJURERCTi1B0jIiIiGaEkRERERDJCSYiIiIhkhAamioiIiKRALSEiIiIRV6nuGBEREckEjQkRERGRjIjqmBAlISIiIhEX1ZYQDUwVERGRjFBLiIiISMSpO0ZEREQyIqrdMUpCREREIi6qLSEaEyIiIiIZoZYQERGRiKvMdAAHSEmIiIhIxEW1O0ZJiIiISMRpYKqIiIhkRFRbQjQwVURERDJCSYiIiEjEOVbvJREzO8vMlpjZMjO7pobt3zSzTWb2XrhcnqhOdceIiIhEXKWnt34zywLuAs4ACoDZZva0uy+qVvQf7n5lsvWqJURERCTiGqElZBSwzN2Xu3sZ8Bgwvr5xKwkRERGJOHer95JAD2B13HpB+F5155nZ+2b2hJn1SlSpkhARERHBzCaY2Zy4ZUL85hp2qd4J9AzQ192PAl4G/promBoTIiIiEnHeAGNC3H0qMLWWzQVAfMtGT2Bttf03x63eC/wm0TGVhNRh1Ih8Jl3Rn1jMePal9TzyZEGV7cMHt2Pi5QPo37c1N962mNfeLty77f99oy/Hj+yImTFn/hbuuHd5Y4ff7I0+Jp9JVwwMr986/vbE6irbhw9pz8QrBjCgbxsm37po7/UbMawDEy8fsLdc756tmPzbRbz5zmbk4HDUvTfTddwplG3czBsjzsl0OFKHY4e347tf700sBs+/WshjT6+vsv28cd0Yd2pnKiqdrcXl3HbPSjYWlmUo2uiqTP9kZbOBQWbWD1gDfA24ML6AmXV393Xh6rnAh4kqVXdMLWIx+NG3B3DVjQu55Mq5jD2xC317tapSZkNhKTffsYSX39hY5f2hR7Rl2JHt+OakeXxj4lyOGNiWo4e2b8zwm71YDH70nUFcNfkDLv7ebMae1HX/67dpFzf/YQkvv76hyvvvfrCVSyfN5dJJc5l43XxKSyuY9e6WxgxfEij461PM+nzCu/8kw2IG37+0Nz/7zUdcdtVCTv1sR3r3yKtSZtnKnXz3ug+Z8NNFvDlzCxMu7JmhaKMt3WNC3L0cuBJ4gSC5eNzdF5rZFDM7Nyw20cwWmtl8YCLwzURxqyWkFkcOasua9btYt2EXAK+8uYkTRnVk5eqde8us31gKgFd7cpA75ObEyM6OYUB2trFlqzL7xnTkoHYUrPuUteH1e/mNjZwwulMN16+0zlvbTh3ThXfmFlFaGtXHQzVNRW/NoWWfmsbEycHk8IGtWbu+lHUbg99/r80oYszIDnyyZl9ryPxFJXtff7hsO6ef0KnR45TkuPs0YFq1926Ie30tcG0qdSbdEmJmY8ysdfj6YjP7nZn1SeVgUdKlUws2FpbuXd+0uYzOnVokte/CJSXM+2Ab/3pgNP96cDSz3t3CqoJP0xWq1KBLp9xq16+ULklev3inn9hlv5YuEUlO5/xcNm7e9wVs0+YyOuXn1lr+rFO6MHv+tsYIrclxr/+SCal0x/wvsNPMhgM/AVYBD6UlqoNVkhepxyF59O3VivMum8mXvjWTY4Z1YPjgdumNTaqwGloWU/0h65SfS/++rZk5T10xIgeipp/D2n6Rnn5CRw7v34rHn1lf43apW2PMmJoOqSQh5e7uBJOT3OHudwBtayscf6vP+pVP1zfORrdpcyldO+/75tylUy6FRaV17LHPScd3YuGSYj7dVcmnuyqZOW8LQw5XEtKYNhaWVbt+LZK+fnucdkIX3pxRSEVFhr4iiETcpqIyunba1/LRpVMum7fs3q/cMUPbcuEXunP9bcvYXa6ftwNR6fVfMiGVJKTEzK4FLgGeC6dwzamtsLtPdfeR7j7ykL7n1lbsoLV4aQk9u+fRvWsLsrON00/swluzipLad8OmUo4e2p6sGGRlGUcPac/Kgp2Jd5QGs3hpMb0ObUn3bnlkZxtjT+rK9Fmp3d0y9qSuvPTGpjRFKNL0Lfl4Bz0OyeOQLrlkZxmnHN+Rt+durVJmYN+W/ODyPtxw2zK2FpdnKNLoa4TJytIilYGpXyW4Hedb7r7ezHoDv01PWJlXUQm/n/oxt08eSixmPPfKBlau3sllF/Zh8bISps8q4oiBbfjVtYNp2yabzx7bkW9d0Juvf38er71dyDHDOvDgHz8DwMx5Rbw9O7kERhpGRSX87u5l/O7GYcH1e3k9Kz7ZyWUX9WXx0hKmz9rMEYPacvPPhtC2TTZjju3EZRf15ZLvzQHgkK4t6NqlBe8t2JrgSJIJRz98O51OHkVu53xOW/E6S6fcyeoHnsh0WFJNZSXc+eAn3HLtYcRi8J/XNrOqYBffOP9QPlqxgxlztzHhwl60zMvi+knBbfEbN5dxw23LMhy5NBbzFDrKw4Gog9z9ZTNrBWS5e0mi/U4c/6ba1yLKK3VXSJRd+58JiQvJQen35z+S6RCknl5+dGSjNS9Mm7e73n9nxx2T0+jNIancHXMF8ARwT/hWD+Bf6QhKREREkleJ1XvJhFTGhHwPGAMUA7j7UqBrOoISERGR5EX1Ft1UxoSUunuZhfdcmVk2Sd+0KiIiIumSqYGl9ZVKS8jrZvYzoKWZnQH8k+CJeSIiIiIpSyUJuQbYBHwAfJtg6tafpyMoERERSV5U5wlJujvG3SsJHs17b/rCERERkVRlakxHfSWdhJjZB+w/BmQbMAe4yd31nHMREZEMyNS06/WVysDU54EK4O/h+tfCf4uBB4FzGi4sERERaepSSULGuPuYuPUPzGy6u48xs4sbOjARERFJTqbGdNRXKgNT25jZ6D0rZjYKaBOuasJ/ERGRDGkO84RcDtxvZm0AI+iGudzMWgO/TkdwIiIikliTH5jq7rOBYWbWnuCZM/FP9nq8wSMTERGRpFRGdLKyVFpCMLPPAUOAvD0zp7r7lDTEJSIiIk1cKrfo3g20Ak4F7gPOB2alKS4RERFJUlS7Y1IZmPpZd/86sMXdbwSOB3qlJywRERFJVnMYmPpp+O9OMzsU2Az0a/iQREREJBVRvUU3lSTkWTPrAPwWmEcwe+p9aYlKREREkhbVp+imcnfML8OXT5rZs0Ceu29LT1giIiLS1CU9JsTMvmxmbcPVq4EHzGxEesISERGRZEV1TEgqA1Ovd/cSMzsB+B/gr8Dd6QlLREREklXp9V8yIZUkpCL893PA/7r7v4Hchg9JREREUtEcWkLWmNk9wFeAaWbWIsX9RURERPZKJYn4CvACcFY4ZXtHgrEhIiIikkFRbQlJ5Rbd7sBz7l5qZqcARwEPpSUqERERSVpU5wlJpSXkSaDCzAYCfyGYqOzvaYlKREREkhbVlpBUkpBKdy8HvgT8wd1/SNA6IiIiIhlUWVn/JREzO8vMlpjZMjO7po5y55uZm9nIRHWmkoTsNrMLgK8Dz4bv5aSwv4iIiESQmWUBdwFnA4OBC8xscA3l2gITgZnJ1JtKEnIpwUPrfuXuK8ysH/C3FPYXERGRNGiE7phRwDJ3X+7uZcBjwPgayv0SuBXYlUzcSSch7r4I+CnBc2Nw9xXufkuy+4uIiEh6NEQSYmYTzGxO3DIh7hA9gNVx6wXhe3uFs6j3cvdnSVLSd8eY2TnAbQQTlPUzs6OBKe5+brJ1iIiISMNriLtj3H0qMLWWzTU9IW/vUc0sBvwe+GYqx0ylO2YyQXPMVgB3f4/gDhkRERHJIHev95JAAdArbr0nsDZuvS0wFHjNzFYCxwFPJxqcmkoSUl7DU3MjemeyiIiIpGA2MMjM+plZLvA14Ok9G919m7t3dve+7t4XeAc4193n1FVpKpOVLTCzC4EsMxtEMPr17VTPQkRERBpWuuf5cPdyM7uSYOb0LOB+d19oZlOAOe7+dN011CyVJOT7wHVAKcEkZS8QjIIVERGRDEpmno/6cvdpwLRq791QS9lTkqkzle6YweGSDeQR3JozO4X9RUREJA2iOmNqKi0hjwBXAQuARsi5REREpClLJQnZ5O7PHMhBBh8/5EB2k4NARYXyzSj7fZtHMh2CHKAfPnFRpkOQ+np0SaMdKqoPsEslCfmFmd0HvEIwLgQAd3+qwaMSERGRpGWqO6W+UklCLgWOIHhezJ6vxw4oCREREckgb5CmkJrmI0uvVJKQ4e4+LG2RiIiIyAGJandMKnfHvFPTE/NEREREDkQqLSEnAN8wsxUEY0IMcHc/Ki2RiYiISFKaw5iQs9IWhYiIiBywyoj2xySdhLj7qnQGIiIiIgemObSEiIiIyEEoqklIKgNTRURERBqMWkJEREQirjKiTSFKQkRERCLOI/qEDSUhIiIiEecRbQnRmBARERHJCLWEiIiIRFylumNEREQkE6LaHaMkREREJOIiOmGqkhAREZGo84hmIRqYKiIiIhmhlhAREZGIi+iQECUhIiIiUdfkn6IrIiIiB6eo3h2jMSEiIiKSEWoJERERiTg9O0ZEREQyQk/RFRERkYyI6pgQJSEiIiIRF9W7YzQwVURERDJCSYiIiEjEudd/ScTMzjKzJWa2zMyuqWH7d8zsAzN7z8zeMrPBiepUEiIiIhJxXun1XupiZlnAXcDZwGDgghqSjL+7+zB3Pxq4Ffhdorg1JkRERCTiGuHumFHAMndfDmBmjwHjgUV7Crh7cVz51kDCoJSEiIiIRFwjPEW3B7A6br0AGF29kJl9D/gRkAuclqhSdceIiIgIZjbBzObELRPiN9ewy36Zj7vf5e4DgJ8CP090TLWEiIiIRFxDtIS4+1Rgai2bC4Beces9gbV1VPcY8L+JjqmWEBERkYir9PovCcwGBplZPzPLBb4GPB1fwMwGxa1+DliaqFK1hIiIiERcuseEuHu5mV0JvABkAfe7+0IzmwLMcfengSvNbCywG9gCfCNRvUpCREREJCF3nwZMq/beDXGvJ6Vap5KQOgzpl8NXxrYiFoO35pfywju7qmwfe2weY4a3oLLS2b7T+eu0HRQVB48y/NIpLRk6IAeAadN3MWdxWaPH39wN6Z/DBWe2JmbGm+/t4vkZn1bZfsaoPE48Oo/KSijZWckDz27fe/3OP60VwwbmEjNYtGI3j764IxOnIKFjh7fju1/vTSwGz79ayGNPr6+y/bxx3Rh3amcqKp2txeXcds9KNhbqZ+5gddS9N9N13CmUbdzMGyPOyXQ4TUJUnx2jMSG1MIMLzmzFnY+XMPnebRw7OJfunap+XJ9sKOfmB7fxy/uLmbukjPNObQnA0AE59OqWzU33F3PLQ8WcOTqPvNxMnEXzZQYXndWGPzxWzPX3bGHUkBZ075xVpcwnGyq46f6tTL5vK3MXl/Hl01sDMKBHNgN75jD53q3cMHUrfbtnc3jvnEychgAxg+9f2puf/eYjLrtqIad+tiO9e+RVKbNs5U6+e92HTPjpIt6cuYUJF/bMULSSjIK/PsWsz1+e6TCalMpKr/eSCUpCatGvezYbt1RSuK2SikqYs6iM4YOqZhIffVLO7vLg9Yq15XRoG3ych3bKYunq3VQ6lO2G1RsrGNJfWUhj6ndoNhuLKijcGly/WYtKOfqwqtdgyardlIXX7+M1u8kPr58DOdlGdhbkZEFWFhTvqGzkM5A9Dh/YmrXrS1m3sYzyCue1GUWMGdmhSpn5i0ooLQuu0YfLttO5o37eDmZFb81hd9G2TIfRpLh7vZdMSNgdY2Yd69ru7kUNF87Bo0NbY0tJxd71LSWV9Du09o9rzFEtWLh8NwCrN5bz+RNa8tKsXeTmGIf3yWbd5opa95WGl982xpaSfYnDluJK+veo/fqdeHQeH3wcNN8vX1PO4lVl3D4p+K//6txdun4Z1Dk/l42b93WtbNpcxhED29Ra/qxTujB7vv7ASfPSCJOVpUUyLSFzgTnhv5uAjwhuu9kUvlej+ElPPpz114aI9aA1ekgufQ7J5sWZwZiRD1eWs+Dj3fz0knZcfm4blq8pj+xjlpuS2hL944a2oE/3bF54Jxgz0jU/RvfO2Vz9xyKu/mMRR/TJYVAvDZ/KFKtpiqRaZoM+/YSOHN6/FY8/s77G7SJycEn4m9Xd+wGY2d3A0+HoWMzsbGBsHfvtnfTk27cURe4v8NYSJ7/tvjEE+W1jbC3Zv0n+iD7ZnH18S27/ezHlcV+Wn5+xi+dnBEnJZee0ZmORmvMb05aSyr3dKwD57WJs3b7/NTiybw6fG9OSWx/etvf6jTi8BcvX7KY0aNjig4/LGNAjh6WryxsjdKlmU1EZXTvt617p0imXzVt271fumKFtufAL3fnxlCXsLo/crxyRemnKLSF7HLsnAQFw9+eBkxs+pIPDynXldO0Yo1P7GFkxGDk4l/nLqv7i69Uti4vPas2fnyyhZOe+/wBm0Dov+PrWo0sWPbpmsWjF/r80JX1Wri2nW8csOofXb9TgFsz/qOrdEr26ZXHJuDbc+XhxletXtK2Cw3rnEDPIisHhvXPUHZNBSz7eQY9D8jikSy7ZWcYpx3fk7blbq5QZ2LclP7i8DzfctoytxUoWpfmpdK/3kgmptDEXmtnPgb8RtIVeDGxOS1QHgUqHx17cyaSvtiVmMP39UtYVVnDOiS1Zta6c95ft5rxTW9Ei15jwhaB/uqi4kj8/uZ2sGFx1cTsAdpU69z+zI5nZ6KQBVTr8/YXt/OCC9sRiMH3+LtYWVjD+pFasXFfO/KXB3TB5OcZ3zguuVdG2Cv70zxLmLC7jiL453DihA+6wYPlu5i/V7Z6ZUlkJdz74CbdcexixGPzntc2sKtjFN84/lI9W7GDG3G1MuLAXLfOyuH7SAAA2bi7jhtuWZThyqc3RD99Op5NHkds5n9NWvM7SKXey+oEnMh1WpEW1JcSSHREbDlD9BXASQRLyBjAlmYGpUeyOkUBFhbqRomzlgpWZDkEO0A+fuCjTIUg9fW73khpHNKXD169fV++/sw/9snujxbtH0i0hYbIxyczauPv2NMYkIiIizUDSY0LM7LNmtghYFK4PN7M/py0yERERSUpUJytLZUzI74H/IXxqnrvPN7OT0hKViIiIJC2qY0JSmvzA3Vdb1Zv2dcuAiIhIhkX12TGpJCGrzeyzgJtZLjAR+DA9YYmIiEhTl0oS8h3gDqAHUAC8CHwvHUGJiIhI8rwymncypnJ3TCGge8ZEREQOMlF9NEgqd8fcambtzCzHzF4xs0IzuzidwYmIiEhiUX2KbirTtp/p7sXA5wm6Yw4Drk5LVCIiIpI0r/R6L5mQShKSE/47Dng0mZlSRURERGqTysDUZ8xsMfAp8F0z6wLsSk9YIiIikqwmP0+Iu19jZr8Bit29wsx2AOPTF5qIiIgko9Kb+N0xZvb1uNfxmx5qyIBEREQkNU2+JQQ4Nu51HnA6MA8lISIiIhnV5JMQd/9+/LqZtQcebvCIREREpFlI6dkx1ewEBjVUICIiInJgmvyzY8zsGWDPWcaAwcDj6QhKREREklfZ1KdtB26Le10OrHL3ggaOR0RERFLUHMaEvF7XdjOb4e7H1z8kERERaQ7qMyakurwGrEtERESS5E19npAkRLMtSEREJOKafHeMiIiIHJyimoSk8gC7RCxxEREREWlolV5Z7yURMzvLzJaY2TIzu6aG7T8ys0Vm9r6ZvWJmfRLVmVISYmaHmNm5ZnaOmR1SbfMlqdQlIiIi0WBmWcBdwNkEU3RcYGaDqxV7Fxjp7kcBTwC3Jqo36STEzC4HZgFfAs4H3jGzb+3Z7u4Lkq1LREREGo5Xer2XBEYBy9x9ubuXAY9R7SG27v6qu+8MV98BeiaqNJUxIVcDI9x9M4CZdQLeBu5PoQ4RERFpYN4Ak5WZ2QRgQtxbU919avi6B7A6blsBMLqO6i4Dnk90zFSSkAKgJG69pFpAIiIikgENMTA1TDim1rK5pnGfNR7UzC4GRgInJzpmwiTEzH4UvlwDzDSzf4cHHk/QPSMiIiIZ1AjzhBQAveLWewJrqxcys7HAdcDJ7l6aqNJkWkLahv9+HC57Mp9/o7lBREREmoPZwCAz60fQKPE14ML4AmY2ArgHOMvdNyZTacIkxN1vDCs/FvgZ0DduPwemJBe/iIiIpENlmucJcfdyM7sSeAHIAu5394VmNgWY4+5PA78F2gD/NDOAT9z93LrqTWVMyN+Aq4AFQDTnhxUREWmCGmJgasJjuE8DplV774a412NTrTOVJGSTuz+T6gFEREQkvaI6Y2oqScgvzOw+4BVg72ATd3+qwaMSERGRJi+VJORS4Aggh33dMQ4oCREREcmg5vAU3eHuPixtkYiIiMgBaQ7dMe+Y2WB3X5S2aERERCRljTEwNR3MPbnsycw+BAYAKwjGhBjg4YNqmjUzmxA3ta1EjK5fdOnaRZuun6SShNT4SF53X9WgEUWQmc1x95GZjkMOjK5fdOnaRZuunyTdHaNkQ0RERBpSLNMBiIiISPOkJKRhqE8z2nT9okvXLtp0/Zq5pMeEiIiIiDQktYSIiIhIRigJaQBm9k0z+1P4erKZXZXpmJo7MzvXzK6px/4/MLNWDRmTiIhUpSREmiR3f9rdb6lHFT8AlISIJOlg+AJmZivNrHMmY5DUKAmpg5l93czeN7P5ZvawmZ1jZjPN7F0ze9nMuiXYf6KZLQrreKyx4m7qzKyvmS02s/vMbIGZPWJmY81supktNbNR1VqnHjSzP5rZ22a23MzOD98/xcyejav3T+F+E4FDgVfN7NVw25lmNsPM5pnZP82sTfj+LXHX+LbG/zQObkleq9Zmdr+ZzQ5/tsaH+w4xs1lm9l74+Q4Kyz4X/kwuMLOvhmVvCPdfYGZTzczC948N951hZr81swXh+1nh+uxw+7fD97ub2RvhMReY2YmZ+uxEmgMlIbUwsyHAdcBp7j4cmAS8BRzn7iOAx4CfJKjmGmBEOKvsd9IZbzM0ELgDOIrgwYoXAicAVwE/q6F893D754E6W0jc/Y/AWuBUdz81/Gb1c2Csux8DzAF+ZGYdgS8CQ8JrfFNDnFgTlOhaXQf8192PBU4FfmtmrQl+Zu5w96OBkUABcBaw1t2Hu/tQ4D/hMf7k7seG77UkuM4ADwDfcffjgYq4mC4DtoXHPBa4wsz6hbG9EB5zOPBew38c0ZNMMhkWHW5m/w3fu6KO+mr8AhC+3i+xN7MuZvZkmDTONrMx4fudzOzFMHm9h2Amb4mQVJ4d09ycBjzh7oUA7l5kZsOAf5hZdyCXYAr7urwPPGJm/wL+ldZom58V7v4BgJktBF5xdzezD4C+NZT/lwePmVyUqAWrBscBg4Hp4RfsXGAGUAzsAu4zs+eAZ2utoXlLdK16Aufavqb8PKA3wWd8nZn1BJ5y96XhPreZ2W+AZ939zXCfU83sJwRdaB2BhWb2JtDW3d8Oy/ydfcnJmcBRe1rFgPbAIGA2cL+Z5RD8n1ESss9A4MvABILPaU8yeS5BMvkeQaJ5HNAaeNfMnnP3tckeIC6xPyL8P9Ih3HQH8Ht3f8vMegMvAEcCvwDecvcpZva5MDaJELWE1M6A6vcv30nwjWsY8G2CX5Z1+Rzw/9u7nxCryjiM49/HAsO0KWpTUWhFC2kxJfSHIETbtDJMKihKcJOQRAvBoEX0B0FdtMgWTYLhkFC2GCFjjDCHFm76QxJBRSkhRgYaY4qp87R43ztzHeaOjXg9enk+MMw959w557335dzz+73v757ZDCwCvpaUoO/iOdX2eKxteYypg+v257eypTOcew506k8Bn9vurz8Lba+yfQa4H/gEeJyJrDzOdb6+EvBE2/t7u+0fbX9IucCdBIYlLbH9E+V82g+sr9Mw1wDvAivquTlA6cvpsmIBa9qOucD2btsjwCPAIWCbpOcu1pvQA36zvb8G8+PBJKUv5tfnDNk+WZO3PZTzYybaA/vlwIm6/lHgHUnfATuB6yTNo/TVIIDtT4GjF/zqohEJQjr7AnhS0o0wHqH3UT6cAJ6f7o8lzQJus72HMm1zPTC3e82NC3AQWChptqQ+YGnbtlFgXn28D3hY0l0AkuZIurvWhfTZ3kUpZO2/hG3vJcPAmrY6jnvr7zuAX+v02E7KyMUtwAnbg8Am4D4mgse/ap+sALB9FBiV9GDd/vSkY66uIx7U/rxW5X9k/Wl7ANhS9x/F/wn8JydunW5ENWUCME1gPwt4qC1ovNX26HmOEVeAZOYd2P5B0lvAXklngW+B14CPJR2iXJgWTLOLq4DBenETZSjxWJebHTNg+3dJH1GmzX6m9HHLe8Bnkg7XupCVwHZJs+v2VymBylDNxAW8fOla31PeAN4Gvq+ByAHKtMlTwLOSTgN/AK9T6jc2ShoDTgOrbR+TNEDJyA9Q2z20jgAAASRJREFUpgpaVgEDkv4BvgT+ruvfp2Tv39RjHqFc9BYDa+sxjwMZCZmZZZLWU6ZjFlPq4qYyngBQApClwFc1iJxje5ekfcAv9fm7gReBjQCS+utU2QjwDPCmpMeAG7rzsqJbcsfUiOhZkubaPl4frwNutv1Sw8264kiaT6nBuacub63LO1rbgB2Ub5XdSanp2VBHlDrtcwOwjJIA/EsZ7RoGhpiYTttk+4NaHL6ZUgdyNTBi+4U6Ur0duAnYCywHFrVq+eLylyAkInqWyld4X6FcuA4CK20fabZVEdGSICQiIiIakZqQiIjoinpbg22TVp+y/UAT7YnLT0ZCIiIiohH5im5EREQ0IkFIRERENCJBSERERDQiQUhEREQ0IkFIRERENOI/e/AEc+nR/DoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Рисуем матрицу корреляции, не учитываем признак tariff\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(data[['calls','minutes','messages','mb_used']].corr(), \n",
    "            annot = True, \n",
    "            cmap='coolwarm')\n",
    "plt.title(f'Матрица корреляции признаков')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обнаружили сильную корреляцию, то есть линейную зависимость, между количеством звонков и потраченных минут. Это можно объяснить тем, что разброс времени условного звонка вероятно невелик, поэтому зависимость линейна. Из теоретического курса знаем, что подобные данные могут помешать обучению некоторых моделей. К тому же, раз зависимость между признаками очевидная, использовать в дальнейшем их оба не обязательно. Поэтому избавимся от признака \"количество звонков\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['calls'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь разделим данные на часть с искомым признаком и часть с признаками, \n",
    "# по которым будет осуществляться предсказание\n",
    "\n",
    "x = data.drop(['is_ultra'], axis=1)\n",
    "y = data['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разделим данные на три выборки - обучающую, валидационную и тестовую в соотношении 80-10-10, т.к. данных не очень много, и для получения качественной модели обучающую выборку следует сделать покрупнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала отделим 80% обучающей выборки, применим параметр stratify для балансировки выборок\n",
    "x_train, x_valid_test, y_train, y_valid_test = train_test_split(x, y, \n",
    "                                                                test_size=0.2, \n",
    "                                                                random_state=12345, \n",
    "                                                                stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь разделим оставшийся кусок на валидионную и тестовую сборки\n",
    "\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_valid_test, y_valid_test,\n",
    "                                                    test_size=0.5,\n",
    "                                                    random_state=12345,\n",
    "                                                    stratify=y_valid_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод по этапу\n",
    "Выявлена сильная линейная зависимость между двумя признаками, один из признаков удалён. Данные разбиты на обучающую, валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изучение моделей и подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Decision Tree\n",
    "\n",
    "В первую очередь рассмотрим модель решающего дерева. Будем изменять гиперпараметр максимальной глубины дерева. Для этого создадим цикл от 2 до 10 включительно. Подбирать результат будем основываясь на точности модели на обучающей и валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для глубины 2\n",
      "Точность модели на обучающей выборке     = 0.780241151302995\n",
      "Точность модели на валидационной выборке = 0.7507788161993769\n",
      "\n",
      "Для глубины 3\n",
      "Точность модели на обучающей выборке     = 0.793465577596266\n",
      "Точность модели на валидационной выборке = 0.7757009345794392\n",
      "\n",
      "Для глубины 4\n",
      "Точность модели на обучающей выборке     = 0.7572928821470245\n",
      "Точность модели на валидационной выборке = 0.7445482866043613\n",
      "\n",
      "Для глубины 5\n",
      "Точность модели на обучающей выборке     = 0.7619603267211202\n",
      "Точность модели на валидационной выборке = 0.7414330218068536\n",
      "\n",
      "Для глубины 6\n",
      "Точность модели на обучающей выборке     = 0.8218591987553481\n",
      "Точность модели на валидационной выборке = 0.794392523364486\n",
      "\n",
      "Для глубины 7\n",
      "Точность модели на обучающей выборке     = 0.8401400233372228\n",
      "Точность модели на валидационной выборке = 0.8006230529595015\n",
      "\n",
      "Для глубины 8\n",
      "Точность модели на обучающей выборке     = 0.838973162193699\n",
      "Точность модели на валидационной выборке = 0.794392523364486\n",
      "\n",
      "Для глубины 9\n",
      "Точность модели на обучающей выборке     = 0.868922598210813\n",
      "Точность модели на валидационной выборке = 0.8006230529595015\n",
      "\n",
      "Для глубины 10\n",
      "Точность модели на обучающей выборке     = 0.8697005056398288\n",
      "Точность модели на валидационной выборке = 0.7819314641744548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Дополнительно укажем гиперпараметр class_weight='balanced'\n",
    "for depth in range (2,11):\n",
    "    tree = DecisionTreeClassifier(random_state=12345,\n",
    "                                  class_weight='balanced',\n",
    "                                  max_depth=depth)\n",
    "    tree.fit(x_train, y_train)\n",
    "    tree_predict = tree.predict(x_valid)\n",
    "    tree_score_train = tree.score(x_train, y_train)\n",
    "    tree_score_valid = tree.score(x_valid, y_valid)\n",
    "    print(f'Для глубины {depth}')\n",
    "    print(f'Точность модели на обучающей выборке     = {tree_score_train}')\n",
    "    print(f'Точность модели на валидационной выборке = {tree_score_valid}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что при макс глубине 8 мы получаем схожий результат по точности на обучающей и валидационной выборке, превосходящий требуемое значение 0.75. Таким образом получаем достаточно точную модель без переобучения. Переобучим модель на заданной глубине и запустим classification_report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели на обучающей выборке     = 0.838973162193699\n",
      "Точность модели на валидационной выборке = 0.794392523364486\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       223\n",
      "           1       0.70      0.58      0.63        98\n",
      "\n",
      "    accuracy                           0.79       321\n",
      "   macro avg       0.76      0.73      0.75       321\n",
      "weighted avg       0.79      0.79      0.79       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=12345,\n",
    "                                  class_weight='balanced',\n",
    "                                  max_depth=8)\n",
    "tree.fit(x_train, y_train)\n",
    "tree_predict = tree.predict(x_valid)\n",
    "tree_score_train = tree.score(x_train, y_train)\n",
    "tree_score_valid = tree.score(x_valid, y_valid)\n",
    "print(f'Точность модели на обучающей выборке     = {tree_score_train}')\n",
    "print(f'Точность модели на валидационной выборке = {tree_score_valid}')\n",
    "print()\n",
    "print(classification_report(y_valid, tree_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения выглядят удовлетворительными. Можем проверить результат на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели решающего дерева на тестовой выборке 0.7546583850931677\n"
     ]
    }
   ],
   "source": [
    "score_tree = tree.score(x_test, y_test)\n",
    "print(f'Точность модели решающего дерева на тестовой выборке {score_tree}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили точность выше 0.75. Далее рассмотрим другие изученные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае решающего леса нужно менять одновременно 2 гиперпараметра. Воспользуемся функцией GridSearchCV для подбора оптимальных гиперпараметров для решающего леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [5, 6, 7, 8, 9, 10],\n",
       "                         'n_estimators': [10, 20, 50, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Задаём гиперпараметры\n",
    "param_grid = {'max_depth': [depth for depth in range(5,11)],\n",
    "             'n_estimators': [10,20,50,100,200]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid=param_grid)\n",
    "\n",
    "# Задаём более крупные выборки (без тестовой) и обучаем гридсёрч\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь выведем получившиеся оптимальные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'n_estimators': 100}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель решающего леса на полученных гиперпараметрах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели на обучающей выборке     = 0.8646441073512252\n",
      "Точность модели на валидационной выборке = 0.8317757009345794\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       223\n",
      "           1       0.79      0.61      0.69        98\n",
      "\n",
      "    accuracy                           0.83       321\n",
      "   macro avg       0.82      0.77      0.79       321\n",
      "weighted avg       0.83      0.83      0.83       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=12345,\n",
    "                                  class_weight='balanced',\n",
    "                                  max_depth=8,\n",
    "                                    n_estimators=50)\n",
    "forest.fit(x_train, y_train)\n",
    "forest_predict = forest.predict(x_valid)\n",
    "forest_score_train = forest.score(x_train, y_train)\n",
    "forest_score_valid = forest.score(x_valid, y_valid)\n",
    "print(f'Точность модели на обучающей выборке     = {forest_score_train}')\n",
    "print(f'Точность модели на валидационной выборке = {forest_score_valid}')\n",
    "print()\n",
    "print(classification_report(y_valid, forest_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили хорошие результаты. Проверим обученную модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели решающего леса на тестовой выборке 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "score_forest = forest.score(x_test, y_test)\n",
    "print(f'Точность модели решающего леса на тестовой выборке {score_forest}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили более высокую точность модели в сравнении с решающим деревом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Logistic Regression\n",
    "\n",
    "Для подбора оптимальных гиперпараметров модели также воспользуемся Гридсёрч."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/peterefimov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 0.25, 0.5, 0.75, 1.0],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В данном случае варьируем параметры пеналти и С\n",
    "param_grid_LR = {'penalty':['l1','l2','elasticnet','none'],\n",
    "                'C':[0.1,0.25,0.5,0.75,1.0]}\n",
    "\n",
    "grid_search_LR = GridSearchCV(LogisticRegression(),param_grid = param_grid_LR)\n",
    "grid_search_LR.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем получившиеся гиперпараметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_LR.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии с полученными гиперпараметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели на обучающей выборке     = 0.7145079735511474\n",
      "Точность модели на валидационной выборке = 0.7165109034267912\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83       223\n",
      "           1       0.71      0.12      0.21        98\n",
      "\n",
      "    accuracy                           0.72       321\n",
      "   macro avg       0.71      0.55      0.52       321\n",
      "weighted avg       0.71      0.72      0.64       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=12345, C=0.1, penalty='l2')\n",
    "lr.fit(x_train, y_train)\n",
    "lr_predict = lr.predict(x_valid)\n",
    "lr_score_train = lr.score(x_train, y_train)\n",
    "lr_score_valid = lr.score(x_valid, y_valid)\n",
    "print(f'Точность модели на обучающей выборке     = {lr_score_train}')\n",
    "print(f'Точность модели на валидационной выборке = {lr_score_valid}')\n",
    "print()\n",
    "print(classification_report(y_valid, lr_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели логистической регрессии на тестовой выборке 0.7018633540372671\n"
     ]
    }
   ],
   "source": [
    "score_lr = lr.score(x_test, y_test)\n",
    "print(f'Точность модели логистической регрессии на тестовой выборке {score_lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили наиболее низкую точность в сравнении с двумя предыдущими моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор оптимальной модели\n",
    "\n",
    "В результате исследования делаем вывод, что наиболее точный результат на тестовой выборке дала модель решающего леса с гиперпараметрами n_estimators = 50, max_depth = 8. Присвоим эту модель новой переменной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_model = forest\n",
    "fine_model_test_score = score_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка адекватности модели\n",
    "\n",
    "Для оценки адекватности полученной модели сравним её результат на тестовой выборке с dummy классификатором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='most_frequent')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим dummy классификатор\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Присвоим ему стратегию выбора наиболее часто встречающегося класса\n",
    "dummy_classifier = DummyClassifier(strategy = 'most_frequent')\n",
    "\n",
    "# Обучим его на обучающей выборке\n",
    "dummy_classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим получившийся массив предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_pred = dummy_classifier.predict(x_valid)\n",
    "display(dummy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все значения одинаковы. Сравним его точность с точностью ранее обученной модели решающего леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность dummy классификатора  = 0.6947040498442367\n",
      "Точность обученной модели леса = 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "dummy_classifier_score = dummy_classifier.score(x_valid, y_valid)\n",
    "print(f'Точность dummy классификатора  = {dummy_classifier_score}')\n",
    "print(f'Точность обученной модели леса = {fine_model_test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность полученной модели выше точности dummy классификатора. Также точность выше заданного уровня - 0.75. Таким образом, в рамках данного проекта обученную модель решающего леса можно считать удовлетворительной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод\n",
    "\n",
    "В рамках проекта были решены задачи:\n",
    "1. Загружен и изучен датасет.\n",
    "2. Выявлены и обработаны признаки с выраженной линейной зависимостью.\n",
    "3. Данные разбиты на обучающую, валидационную и тестовую выборки.\n",
    "4. Изучены 3 модели - решающее дерево, лес и логистическая регрессия. К ним подобраны оптимальные гиперпараметры, на полученных гиперпараметрах модели обучены, получены значения их точности на тестовых выборках.\n",
    "5. Определена модель решающего леса как наиболее точная.\n",
    "6. Модель проверена на адекватность. Достигнут заданный уровень точности модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
